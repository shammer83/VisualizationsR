---
title: "L09-Assignment"
output: html_notebook
---

# Assignment Instructions

* Complete all cells as instructed, replacing any ??? with the appropriate code

* Execute RStudio **Session** > **Restart & Run All Chunks** and ensure that all code blocks run without error

* Do not load any additional libraries. You must use the libraries in the Load Libraries cell provided.

* Meet all of the assignment objectives described below

* RStudio Notebook cells can be added and inserted as desired

# Assignment Objectives


Classify iris flower species. This includes:

* 1 point - All code blocks run without error. RStudio **Session** > **Restart & Run All Chunks**
* 1 point - Create 2 classification models, with at least one multivariate classification model
* 1 point - Confusion matrix for each model
* 1 point - Chart visualization for each model
* 1 point - Training set and testing set for each model
* 1 point - Include the following R Features at least once. You are not limited to these, only by the libraries loaded.
* 1 point - Include a written analysis of iris species category performance referencing the confusion matrix as evidence of your conclusions.

The above is what is required to achieve full credit for the assignment. You are welcome and encouraged to go above and beyond these requirements, just be sure these requirements are fully met first. 


## R Features
* caret::confusionMatrix()
* set.seed()
* glm()
* predict()

## Dataset
* iris

```{r}
# Load libraries
# Do not load any additional libraries other than what is provided in this template

# You can reference the caret package using caret::<function>
library(lubridate)
library(tidyverse)
```

```{r}
# Explore data structure
# Data: iris
iris %>% glimpse()

# Display help on data
? iris

cat('\nSummary of iris data\n')
iris %>% summary()

#we want to predict class versicolor 
iris_copy <- iris %>%
  mutate(Species = if_else(Species == 'versicolor', 'versicolor', 'not versicolor') %>% as.factor())

#explore result

iris_copy %>% glimpse()

#display frequency of target label
iris_copy$Species %>% table()

```
```{r}
cols <- iris_copy %>%
  select(-Species)%>% 
  names()

cols %>% print()

plot.species <- function( col, df){
  p1 <- df %>% 
      ggplot(aes_string('Species', col)) + 
      geom_violin (draw_quantiles = c(0.25, 0.5, 0.75), 
              fill = 'blue', alpha = 0.3, size = 1.0)
  
    p1 %>% print ()
  
}

# Hint: walk()
cols %>% walk(plot.species, iris_copy)
```
```{r}
plot.species.d <- function(col, df, bins = 60){
    binwidth <- (max(df[, col]) - min(df[, col])) / bins
    p1 <- ggplot(df, aes_string(col)) + 
           geom_dotplot (dotsize = 0.5, method = "histodot", binwidth = binwidth) +
           facet_wrap ( ~ Species)
    
    p1 %>% print ()
}

# Call plot function for each value in cols
# Hint: walk()
cols %>% walk (plot.species.d, iris_copy)
```
```{r}
# build into a plotting function
iris_copy %>%
  gather(-Sepal.Length, -Species, key = 'var', value = 'value')%>%
  ggplot(aes(x = value, y = Sepal.Length, fill = Species))+ 
  geom_point()+
  stat_smooth()+
  facet_wrap(~ var, scales = "free")+
  theme_classic()

iris_copy %>%
  gather(-Sepal.Width, -Species, key = 'var', value = 'value')%>%
  ggplot(aes(x = value, y = Sepal.Width, fill = Species))+ 
  geom_point()+
  stat_smooth()+
  facet_wrap(~ var, scales = "free")+
  theme_classic()

iris_copy %>%
  gather(-Petal.Length, -Species, key = 'var', value = 'value')%>%
  ggplot(aes(x = value, y = Petal.Length, fill = Species))+ 
  geom_point()+
  stat_smooth()+
  facet_wrap(~ var, scales = "free")+
  theme_classic()

iris_copy %>%
  gather(-Petal.Width, -Species, key = 'var', value = 'value')%>%
  ggplot(aes(x = value, y = Petal.Width, fill = Species))+ 
  geom_point()+
  stat_smooth()+
  facet_wrap(~ var, scales = "free")+
  theme_classic()
```


# Data processing
Create a new data frame(s) with appropriate data types and data cleaning for the data.

```{r}
# Remove duplicate rows
print(str_c("Original row count: ",iris_copy %>% nrow()))
iris_copy <- iris_copy %>% distinct ()

print(str_c("distinctated row count: ", iris_copy %>% nrow()))

normalize <- function(x) (x - mean(x)) / sd(x)

iris_copy <- iris_copy %>% 
  mutate_at(vars(-Species), normalize)

iris_copy %>% glimpse()
```
```{r}
#Training the classifier

set.seed(42)

#split data into training and test sets
df_train <- iris_copy %>%
  sample_frac(0.7)

df_test <- iris_copy %>% 
  setdiff(df_train)

#display row counts of training and test
print(str_c("training rows: ", nrow(df_train)))
print(str_c("test rows: ", nrow(df_test)))

#compare train and test to original data frame

nrow(df_train) + nrow(df_test) == nrow(iris_copy)

df_test_orig <- df_test

df_train_orig <- df_train

```
```{r}

versi_mod1 <- glm(Species ~ Petal.Width, data = df_train, family = binomial())


#Scoring the model
df_test$score1 <- predict(versi_mod1, newdata = df_test)

# Transform using logistic function
df_test<- df_test %>%
  mutate(score1.prob = exp(score1)/ 1+exp(score1))

df_test %>% summary()

df_test %>% ggplot(aes(Species, score1.prob)) +
  geom_violin ( draw_quantiles  = c(0.25, 0.5, 0.75), 
              fill = 'blue', alpha = 0.3, size = 1.0) +
  labs(title="Model Score by Species", 
       x="Species of Iris", y="Score value")

#View summary of model

versi_mod1 %>%summary()

versi_mod1 %>% confint()
```
### Analysis
This model is not well fit.  

- The standard error of all the coefficients are not an order of magnitude smaller than the coefficient values themselves. 

- The p-value of the Petal.Width coefficient isn't small enough to indicate that Petal width was significant in the classification. 

- There is not a notable difference between the Null deviance and the Residual Deviance to suggest that the model is explaining some variation in the Petal.Width data. 

```{r}
#Training our second classifier

df_train <- df_train_orig # reset our trainining data

df_test2 <- df_test_orig

versi_mod2<- glm(Species ~ ., data = df_train, family = binomial())

df_test2 <- df_test2 %>%
  mutate(score2 = predict(versi_mod2, newdata = df_test2))

# Transform with the logistic function
df_test2 <- df_test2 %>%
  mutate(score2.prob = exp(score2)/ 1+exp(score2))

df_test2 %>% summary()

df_test2 %>% ggplot(aes(Species, score2.prob)) +
  geom_violin ( draw_quantiles  = c(0.25, 0.5, 0.75), 
              fill = 'blue', alpha = 0.3, size = 1.0) +
  labs(title="Model Score by Species", 
       x="Species of Iris", y="Score value")


#View summary of model

versi_mod2 %>%summary()

versi_mod2 %>% confint()

```
### Analysis
This model fit better.  

- We can identify that the Sepal.Width coefficient (as well as the intercept) are significant coefficients in predicting the classification 

- There is a a notable difference between the Null deviance and the Residual Deviance to suggest that the model is explaining some variation in the data. 
```{r}
# try building the model using just Sepal Width
df_train <- df_train_orig # reset our trainining data

df_test3 <- df_test_orig

versi_mod3 <- glm(Species ~ Sepal.Width, data = df_train, family = binomial())

df_test3 <- df_test3 %>%
  mutate(score3 = predict(versi_mod3, newdata = df_test3))

# Transform with the logistic function
df_test3 <- df_test3 %>%
  mutate(score3.prob = exp(score3)/ 1+exp(score3))

df_test3 %>% summary()

df_test3 %>% ggplot(aes(Species, score3.prob)) +
  geom_violin (draw_quantiles  = c(0.25, 0.5, 0.75), 
              fill = 'blue', alpha = 0.3, size = 1.0) +
  labs(title="Model Score by Species", 
       x="Species of Iris", y="Score value")

versi_mod3 %>%summary()

versi_mod3 %>% confint()

```
### Analysis

This model is the best fit of the three used to classify versicolor. 

-By eliminating the noise of the other features, we were able to acieve the lowest AIC score

```{r}
### Taking a closer look at the Third model

# Calculate binwidth for dotplot
binwidth = (max(df_test3[, 'score3.prob']) - min (df_test3[, 'score3.prob'])) / 60
# Create dotplot using above binwidth for x = score
# facet on left
# Hint: geom_dotplot(), facet_wrap()
ggplot(df_test3, aes(x = score3.prob)) + 
       geom_dotplot(dotsize = 0.5, method = "histodot", binwidth = binwidth) +
  facet_wrap ( ~ Species) +
  labs(title="Model Score by Versicolor or Non-versicolor",
       x="Score count", y="Count")

df_test3 <- df_test3 %>% mutate(score3.pred = if_else(score3.prob > 0.5, "versicolor", "not versicolor") %>% as.factor())

### Evaluating our classifier

caret::confusionMatrix(data = df_test3$Species, reference = df_test3$score3.pred, mode = "prec_recall")

```
```{r}

test.threshold <- function(thresh = 0.5, data) {
  
  # Calculat the new prediction based on the threshold
  data <- data %>% mutate (score3.pred = if_else(data$score3.prob > thresh, 'versicolor', 'not versicolor') %>% as.factor())
  cat('For threshold of ', thresh, ' performance is: \n')
  print(caret::confusionMatrix(data = data$Species, reference = data$score3.pred, mode = "prec_recall"))
  cat('\n')
  
  
}

threshs = c(0.8, 0.75, 0.7, 0.65, 0.6, 0.55, 0.45, 0.40, 0.35, 0.30)

threshs %>% walk(test.threshold, df_test3)

```
```{r}

df_test3$Species %>% table()
```

# Analysis and Conclusions

Of the thresholds evaluated - the best performing threshold was 0.70 when optimizing on model accuracy and precision score (respectively 0.6889 and 0.5714).  However if Recall or F1 are your metrics for optimization, then you would want to select a Threshold of 0.45.  

Looking at our confusion matrix,  Our model set with a 0.70 threshold had high True Positives for the positive class of "Not Versicolor" and High True Negatives for the Negative Class "Versicolor." However, they also Had high number of False Positives for "Not Versicolor" which ultimately lowered our score of making accurate predictions.   

My best classifier only performed marginally better than a naiver prediction. In my test set,  we had 28 not versicolor, and 17 versicolor iris,  which means a naive guess would suggest that,  28/45 or 0.62,  would be not Versicolor. My Final accuracy prediction only reached 0.6889.  
