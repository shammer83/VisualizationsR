{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L03-2-Reading Excel Files\n",
    "## Assignment Instructions\n",
    "Rename with your name in place of Studentname and make your edits and updates here.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading Excel Files\n",
    "\n",
    "Excel is a common type of source data. It can get a bit messy if that Excel file was generated by a human rather than an automated process, but this is a welcomed data wrangling challenge. There are times when things are going all wrong that I simply open up the Excel file, make any edits or column formatting changes, and save as CSV. There, now I have a CSV file that I can easily import. \n",
    "\n",
    "That is a last resort. R has numerous ways to import Excel files just as it does for flat files. In fact, there are packages that both read AND write to Excel. Yes, you can programmatically edit Excel using R. In this course, however, we will stick to the tidyverse Excel import which is pretty simple and basic, but the package is under active development so more features are coming.\n",
    "\n",
    "In this exercise, you will read in Excel files, both the older xls format and the newer xlsx format. We will use the readxl package. It was developed by Hadley Wickham, the same author of the readr package we used in the prior exercise, so the syntax will be familiar. readxl doesn't load with the tidyverse so we will have load the package with its own library command.\n",
    "\n",
    "There are only two functions in the readxl package at this time. excel_sheets() and read_excel(). The first returns a list of sheet names for a given file. The second returns a data frame for a given Excel file and sheet. Pretty simple.\n",
    "The readxl package comes with two example files. We'll take this opportunity to learn how to find and copy these files to our current working directory.\n",
    "\n",
    "We will then use excel_sheets() to get a list of sheet names and use that with read_excel() to load sheets into R data frames.\n",
    "\n",
    "There are two read_csv features I miss the most that are not yet in read_excel(). The first is the ability to distinguish between double and integer data types. The second is trimming whitespace. Both of these tasks can easily be performed after they are in a data frame. We'll see how to convert to integer in this exercise and we'll leave string manipulation to a later exercise. Read_csv does both of these things by default. What I find myself doing is reading in the excel file, exporting to csv and reading the csv back in. Then I get all the features I was missing from read_excel(). Call me lazy, but all but the biggest Excel sheets can perform this double import in under a second. Anything that saves me some data wrangling time is good in my book.\n",
    "\n",
    "We will import an Excel file where the user (okay it was me pretending to be a user) filtered the data on two different Excel table sheets to different years. We import both sheets. After we get two data frames, one for the rows from year 1999 and the other for year 2008, we combine them together using bind_rows() a handy tidyverse dplyr function. This is similar to SQL UNION ALL. If you had a number of spreadsheets where the columns are all the same but filtered by some variable, R can do a great job automating the combining of this data into a single data set.\n",
    "\n",
    "We then tackle a more challenging FORMATTED spreadsheet that has a merged cell title and some empty rows and columns as well as some miscellaneous manual cell formatting and notes outside of the main table of data. These manually prettified spreadsheets can be more challenging to deal with and don't load in very well by default. The default import will \"shrink-wrap\" the spreadsheet into an enclosing rectangle that contains all of the information, which includes the title at the top of the sheet and any other straggling non-empty cells. The idea is that it is not ignoring any data from the sheet, thus you get a mess of string columns and missing values all over the place….but all the data from the sheet is technically in a data frame. Skipping the first few rows and using select() to get the subset of columns, allowed us to recover the original data set quite easily, much easier than wrangling an out-of-control data frame we would have had.\n",
    "\n",
    "\n",
    "## R Features\n",
    "* library() - load libraries needed\n",
    "* system.file()\n",
    "* dir() - list of files in current directory\n",
    "* file.copy()\n",
    "* getwd() - gets current working directory\n",
    "* ? - help\n",
    "* excel_sheets()\n",
    "* read_excel()\n",
    "* glimpse()\n",
    "* mutate()\n",
    "* as.integer()\n",
    "* filter()\n",
    "* bind_rows()\n",
    "* select()\n",
    "* drop_na()\n",
    "\n",
    "## Datasets\n",
    "* datasets.xls(x)\n",
    "* multi_sheet_xlsx.xlsx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The downloaded binary packages are in\n",
      "\t/var/folders/wj/xznnsc017lx9jyb9bf96vy_dk7qypq/T//RtmpTub1E5/downloaded_packages\n"
     ]
    }
   ],
   "source": [
    "# One time package installation\n",
    "# No need to run, should already be installed\n",
    "# For your reference only\n",
    "# install.packages(\"readxl\", repos = \"https://cloud.r-project.org\")\n",
    "\n",
    "# Load libraries\n",
    "library(tidyverse)\n",
    "\n",
    "# readxl is not loaded as part of the tidyverse\n",
    "# but it will likely be added in the future\n",
    "# So we load it separately\n",
    "\n",
    "install.packages(\"readxl\", repos = \"https://cloud.r-project.org\")\n",
    "\n",
    "library ('readxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata'"
      ],
      "text/latex": [
       "'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata'"
      ],
      "text/markdown": [
       "'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata'"
      ],
      "text/plain": [
       "[1] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# readxl like many packages\n",
    "# contains sample data\n",
    "# Let's copy the sample Excel files\n",
    "\n",
    "# The files are copied as part of \n",
    "# package installation\n",
    "# Let's figure out where that turned\n",
    "# out to be\n",
    "\n",
    "# The sample files are in a subfolder\n",
    "# named extdata\n",
    "# Use system.file() to display the path\n",
    "system.file(\"extdata\", package = 'readxl')\n",
    "\n",
    "# We could save this path as a variable if we like\n",
    "# but if it is only used one time\n",
    "# I try to use the %>% instead of assigning a\n",
    "# variable to the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/clippy.xls'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/clippy.xlsx'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/datasets.xls'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/datasets.xlsx'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/deaths.xls'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/deaths.xlsx'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/geometry.xls'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/geometry.xlsx'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/type-me.xls'</li>\n",
       "\t<li>'/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/type-me.xlsx'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/clippy.xls'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/clippy.xlsx'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/datasets.xls'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/datasets.xlsx'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/deaths.xls'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/deaths.xlsx'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/geometry.xls'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/geometry.xlsx'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/type-me.xls'\n",
       "\\item '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/type-me.xlsx'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/clippy.xls'\n",
       "2. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/clippy.xlsx'\n",
       "3. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/datasets.xls'\n",
       "4. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/datasets.xlsx'\n",
       "5. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/deaths.xls'\n",
       "6. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/deaths.xlsx'\n",
       "7. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/geometry.xls'\n",
       "8. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/geometry.xlsx'\n",
       "9. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/type-me.xls'\n",
       "10. '/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/type-me.xlsx'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/clippy.xls\"   \n",
       " [2] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/clippy.xlsx\"  \n",
       " [3] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/datasets.xls\" \n",
       " [4] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/datasets.xlsx\"\n",
       " [5] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/deaths.xls\"   \n",
       " [6] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/deaths.xlsx\"  \n",
       " [7] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/geometry.xls\" \n",
       " [8] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/geometry.xlsx\"\n",
       " [9] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/type-me.xls\"  \n",
       "[10] \"/Library/Frameworks/R.framework/Versions/3.6/Resources/library/readxl/extdata/type-me.xlsx\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recall that we can display the contents\n",
    "# of a folder using dir()\n",
    "\n",
    "# Let's display the names of the\n",
    "# files in the readxl extdata folder\n",
    "# Since I want the full path along with the \n",
    "# filenames I will set parameter full.names = TRUE\n",
    "system.file(\"extdata\", package = \"readxl\") %>% \n",
    "   dir(full.names = TRUE)\n",
    "\n",
    "# Notice there are two files, one xls and the other xlsx\n",
    "# Both contain the same data\n",
    "\n",
    "# Open these files from within Excel\n",
    "# and look at the data and sheets\n",
    "# Be sure to close Excel after you are done so\n",
    "# it doesn't lock the file from accessing it from R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "?file.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "\t<li>TRUE</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\item TRUE\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. TRUE\n",
       "2. TRUE\n",
       "3. TRUE\n",
       "4. TRUE\n",
       "5. TRUE\n",
       "6. TRUE\n",
       "7. TRUE\n",
       "8. TRUE\n",
       "9. TRUE\n",
       "10. TRUE\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Although the code is getting a bit long\n",
    "# let's take the prior code that produced two full \n",
    "# file paths pass it to the file.copy() function\n",
    "# to copy it to our current working directory\n",
    "file.copy(from = system.file(\"extdata\", package = \"readxl\") %>% \n",
    "             dir(full.names = TRUE), \n",
    "          to = getwd())\n",
    "\n",
    "# Notice the output of TRUE TRUE\n",
    "# This indicates that both files were copied successfully\n",
    "\n",
    "# Run this code block a second time and \n",
    "# it should output FALSE FALSE indicating that \n",
    "# the files were not copied. This is expected\n",
    "# because the files already exist in the destination\n",
    "# and the default behavior of file.copy() is to not overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'1-1.ipynb'</li>\n",
       "\t<li>'1-2.ipynb'</li>\n",
       "\t<li>'1.1.nb.html'</li>\n",
       "\t<li>'1.1.Rmd'</li>\n",
       "\t<li>'auto.csv'</li>\n",
       "\t<li>'BIG-IQ_Zach.ipynb'</li>\n",
       "\t<li>'clippy.xls'</li>\n",
       "\t<li>'clippy.xlsx'</li>\n",
       "\t<li>'datasets.xls'</li>\n",
       "\t<li>'datasets.xlsx'</li>\n",
       "\t<li>'deaths.xls'</li>\n",
       "\t<li>'deaths.xlsx'</li>\n",
       "\t<li>'geometry.xls'</li>\n",
       "\t<li>'geometry.xlsx'</li>\n",
       "\t<li>'L01-Assignment.ipynb'</li>\n",
       "\t<li>'L01-E2-Scatterplots.ipynb'</li>\n",
       "\t<li>'L02-Assignment_DHaynes.ipynb'</li>\n",
       "\t<li>'L02-E1-Trendlines.ipynb'</li>\n",
       "\t<li>'L02-E2-Overplotting.ipynb'</li>\n",
       "\t<li>'L02-E3-Categorical.ipynb'</li>\n",
       "\t<li>'L02-E4-Filtering.ipynb'</li>\n",
       "\t<li>'L02-E5-Piping.ipynb'</li>\n",
       "\t<li>'L02-E6-Select.ipynb'</li>\n",
       "\t<li>'L03-E1-ReadingFlatFiles.ipynb'</li>\n",
       "\t<li>'L03-E2-ReadingExcelFiles.ipynb'</li>\n",
       "\t<li>'L03-E3-ImportingFromInternet.ipynb'</li>\n",
       "\t<li>'L03-E4-SqlImport.ipynb'</li>\n",
       "\t<li>'L03-E5-DataTypeConversion.ipynb'</li>\n",
       "\t<li>'mpg.csv'</li>\n",
       "\t<li>'mpg.tsv'</li>\n",
       "\t<li>'mtcars.csv'</li>\n",
       "\t<li>'mtcars.xls'</li>\n",
       "\t<li>'README.md'</li>\n",
       "\t<li>'type-me.xls'</li>\n",
       "\t<li>'type-me.xlsx'</li>\n",
       "\t<li>'Visualizations-RfoDataScience.R'</li>\n",
       "\t<li>'VisualizationsR'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '1-1.ipynb'\n",
       "\\item '1-2.ipynb'\n",
       "\\item '1.1.nb.html'\n",
       "\\item '1.1.Rmd'\n",
       "\\item 'auto.csv'\n",
       "\\item 'BIG-IQ\\_Zach.ipynb'\n",
       "\\item 'clippy.xls'\n",
       "\\item 'clippy.xlsx'\n",
       "\\item 'datasets.xls'\n",
       "\\item 'datasets.xlsx'\n",
       "\\item 'deaths.xls'\n",
       "\\item 'deaths.xlsx'\n",
       "\\item 'geometry.xls'\n",
       "\\item 'geometry.xlsx'\n",
       "\\item 'L01-Assignment.ipynb'\n",
       "\\item 'L01-E2-Scatterplots.ipynb'\n",
       "\\item 'L02-Assignment\\_DHaynes.ipynb'\n",
       "\\item 'L02-E1-Trendlines.ipynb'\n",
       "\\item 'L02-E2-Overplotting.ipynb'\n",
       "\\item 'L02-E3-Categorical.ipynb'\n",
       "\\item 'L02-E4-Filtering.ipynb'\n",
       "\\item 'L02-E5-Piping.ipynb'\n",
       "\\item 'L02-E6-Select.ipynb'\n",
       "\\item 'L03-E1-ReadingFlatFiles.ipynb'\n",
       "\\item 'L03-E2-ReadingExcelFiles.ipynb'\n",
       "\\item 'L03-E3-ImportingFromInternet.ipynb'\n",
       "\\item 'L03-E4-SqlImport.ipynb'\n",
       "\\item 'L03-E5-DataTypeConversion.ipynb'\n",
       "\\item 'mpg.csv'\n",
       "\\item 'mpg.tsv'\n",
       "\\item 'mtcars.csv'\n",
       "\\item 'mtcars.xls'\n",
       "\\item 'README.md'\n",
       "\\item 'type-me.xls'\n",
       "\\item 'type-me.xlsx'\n",
       "\\item 'Visualizations-RfoDataScience.R'\n",
       "\\item 'VisualizationsR'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '1-1.ipynb'\n",
       "2. '1-2.ipynb'\n",
       "3. '1.1.nb.html'\n",
       "4. '1.1.Rmd'\n",
       "5. 'auto.csv'\n",
       "6. 'BIG-IQ_Zach.ipynb'\n",
       "7. 'clippy.xls'\n",
       "8. 'clippy.xlsx'\n",
       "9. 'datasets.xls'\n",
       "10. 'datasets.xlsx'\n",
       "11. 'deaths.xls'\n",
       "12. 'deaths.xlsx'\n",
       "13. 'geometry.xls'\n",
       "14. 'geometry.xlsx'\n",
       "15. 'L01-Assignment.ipynb'\n",
       "16. 'L01-E2-Scatterplots.ipynb'\n",
       "17. 'L02-Assignment_DHaynes.ipynb'\n",
       "18. 'L02-E1-Trendlines.ipynb'\n",
       "19. 'L02-E2-Overplotting.ipynb'\n",
       "20. 'L02-E3-Categorical.ipynb'\n",
       "21. 'L02-E4-Filtering.ipynb'\n",
       "22. 'L02-E5-Piping.ipynb'\n",
       "23. 'L02-E6-Select.ipynb'\n",
       "24. 'L03-E1-ReadingFlatFiles.ipynb'\n",
       "25. 'L03-E2-ReadingExcelFiles.ipynb'\n",
       "26. 'L03-E3-ImportingFromInternet.ipynb'\n",
       "27. 'L03-E4-SqlImport.ipynb'\n",
       "28. 'L03-E5-DataTypeConversion.ipynb'\n",
       "29. 'mpg.csv'\n",
       "30. 'mpg.tsv'\n",
       "31. 'mtcars.csv'\n",
       "32. 'mtcars.xls'\n",
       "33. 'README.md'\n",
       "34. 'type-me.xls'\n",
       "35. 'type-me.xlsx'\n",
       "36. 'Visualizations-RfoDataScience.R'\n",
       "37. 'VisualizationsR'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \"1-1.ipynb\"                          \"1-2.ipynb\"                         \n",
       " [3] \"1.1.nb.html\"                        \"1.1.Rmd\"                           \n",
       " [5] \"auto.csv\"                           \"BIG-IQ_Zach.ipynb\"                 \n",
       " [7] \"clippy.xls\"                         \"clippy.xlsx\"                       \n",
       " [9] \"datasets.xls\"                       \"datasets.xlsx\"                     \n",
       "[11] \"deaths.xls\"                         \"deaths.xlsx\"                       \n",
       "[13] \"geometry.xls\"                       \"geometry.xlsx\"                     \n",
       "[15] \"L01-Assignment.ipynb\"               \"L01-E2-Scatterplots.ipynb\"         \n",
       "[17] \"L02-Assignment_DHaynes.ipynb\"       \"L02-E1-Trendlines.ipynb\"           \n",
       "[19] \"L02-E2-Overplotting.ipynb\"          \"L02-E3-Categorical.ipynb\"          \n",
       "[21] \"L02-E4-Filtering.ipynb\"             \"L02-E5-Piping.ipynb\"               \n",
       "[23] \"L02-E6-Select.ipynb\"                \"L03-E1-ReadingFlatFiles.ipynb\"     \n",
       "[25] \"L03-E2-ReadingExcelFiles.ipynb\"     \"L03-E3-ImportingFromInternet.ipynb\"\n",
       "[27] \"L03-E4-SqlImport.ipynb\"             \"L03-E5-DataTypeConversion.ipynb\"   \n",
       "[29] \"mpg.csv\"                            \"mpg.tsv\"                           \n",
       "[31] \"mtcars.csv\"                         \"mtcars.xls\"                        \n",
       "[33] \"README.md\"                          \"type-me.xls\"                       \n",
       "[35] \"type-me.xlsx\"                       \"Visualizations-RfoDataScience.R\"   \n",
       "[37] \"VisualizationsR\"                   "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'clippy.xlsx'</li>\n",
       "\t<li>'datasets.xlsx'</li>\n",
       "\t<li>'deaths.xlsx'</li>\n",
       "\t<li>'geometry.xlsx'</li>\n",
       "\t<li>'type-me.xlsx'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'clippy.xlsx'\n",
       "\\item 'datasets.xlsx'\n",
       "\\item 'deaths.xlsx'\n",
       "\\item 'geometry.xlsx'\n",
       "\\item 'type-me.xlsx'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'clippy.xlsx'\n",
       "2. 'datasets.xlsx'\n",
       "3. 'deaths.xlsx'\n",
       "4. 'geometry.xlsx'\n",
       "5. 'type-me.xlsx'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"clippy.xlsx\"   \"datasets.xlsx\" \"deaths.xlsx\"   \"geometry.xlsx\"\n",
       "[5] \"type-me.xlsx\" "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/latex": [],
      "text/markdown": [],
      "text/plain": [
       "character(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List the files in the current working directory\n",
    "# to confirm the sample files were copied\n",
    "dir()\n",
    "\n",
    "# To display just the Excel files\n",
    "# we can pass a filter pattern to\n",
    "# dir(). The pattern string is \n",
    "# interpreted as a regular expression\n",
    "# See if you can create a pattern \n",
    "# that returns only xls and xlsx files\n",
    "dir(pattern = \"xlsx\")\n",
    "\n",
    "# For you regex folks, the below one is more accurate\n",
    "# as it looks for the extension at the end of the file \n",
    "# only\n",
    "# The . is escaped by two backslashes\n",
    "# so it matches the period character and not\n",
    "# any character\n",
    "# The {0, 1} means 0 to 1 occurrences of the prior character\n",
    "# so the x could be missing or occur once\n",
    "# The $ means end of string\n",
    "dir(pattern = \"\\\\.xlsx[0,1]$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'/Users/dhaynes/Documents/Data_science/VisualizationsR'"
      ],
      "text/latex": [
       "'/Users/dhaynes/Documents/Data\\_science/VisualizationsR'"
      ],
      "text/markdown": [
       "'/Users/dhaynes/Documents/Data_science/VisualizationsR'"
      ],
      "text/plain": [
       "[1] \"/Users/dhaynes/Documents/Data_science/VisualizationsR\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "getwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have the files in our \n",
    "# Current working directory\n",
    "# We first need to look at the sheets\n",
    "# to figure out which ones to import\n",
    "\n",
    "# Let's pull up help on \n",
    "# excel_sheets()\n",
    "?excel_sheets()\n",
    "\n",
    "# Notice there is a single argument, path\n",
    "# In R, path refers to the filename and \n",
    "# if desired the folder path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'iris'</li>\n",
       "\t<li>'mtcars'</li>\n",
       "\t<li>'chickwts'</li>\n",
       "\t<li>'quakes'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'iris'\n",
       "\\item 'mtcars'\n",
       "\\item 'chickwts'\n",
       "\\item 'quakes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'iris'\n",
       "2. 'mtcars'\n",
       "3. 'chickwts'\n",
       "4. 'quakes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"iris\"     \"mtcars\"   \"chickwts\" \"quakes\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'iris'</li>\n",
       "\t<li>'mtcars'</li>\n",
       "\t<li>'chickwts'</li>\n",
       "\t<li>'quakes'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 'iris'\n",
       "\\item 'mtcars'\n",
       "\\item 'chickwts'\n",
       "\\item 'quakes'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 'iris'\n",
       "2. 'mtcars'\n",
       "3. 'chickwts'\n",
       "4. 'quakes'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] \"iris\"     \"mtcars\"   \"chickwts\" \"quakes\"  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's display the sheet names of\n",
    "# both datasets Excel files\n",
    "\n",
    "# file: datasets.xls\n",
    "excel_sheets('datasets.xls')\n",
    "\n",
    "# file: datasets.xlsx\n",
    "excel_sheets(\"datasets.xlsx\")\n",
    "\n",
    "# Notice that both files contain the same sheet names\n",
    "# They are listed in the order in which they \n",
    "# appear in Excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We know the filename and sheet names\n",
    "# So let's look at read_excel()\n",
    "# Pull up help on this\n",
    "?read_excel()\n",
    "\n",
    "# Notice its similarity to read_csv()\n",
    "# That is no coincidence since both packages\n",
    "# were written by Hadley Wickham\n",
    "# readxl is not yet as full featured as readr package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read_excel Arguments\n",
    "### path\t\n",
    "Path to the xls/xlsx file\n",
    "### sheet\t\n",
    "Sheet to read. Either a string (the name of a sheet), or an integer (the position of the sheet). Defaults to the first sheet.\n",
    "### col_names\t\n",
    "Either TRUE to use the first row as column names, FALSE to number columns sequentially from X1 to Xn, or a character vector giving a name for each column.\n",
    "### col_types\t\n",
    "Either NULL to guess from the spreadsheet or a character vector containing \"blank\", \"numeric\", \"date\" or \"text\".\n",
    "### na\t\n",
    "Missing value. By default readxl converts blank cells to missing data. Set this value if you have used a sentinel value for missing values.\n",
    "### skip\t\n",
    "Number of rows to skip before reading any data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 150\n",
      "Variables: 5\n",
      "$ Sepal.Length \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 5.1, 4.9, 4.7, 4.6, 5.0, 5.4, 4.6, 5.0, 4.4, 4.9, 5.4, 4…\n",
      "$ Sepal.Width  \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 3.5, 3.0, 3.2, 3.1, 3.6, 3.9, 3.4, 3.4, 2.9, 3.1, 3.7, 3…\n",
      "$ Petal.Length \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 1.4, 1.4, 1.3, 1.5, 1.4, 1.7, 1.4, 1.5, 1.4, 1.5, 1.5, 1…\n",
      "$ Petal.Width  \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 0.2, 0.2, 0.2, 0.2, 0.2, 0.4, 0.3, 0.2, 0.2, 0.1, 0.2, 0…\n",
      "$ Species      \u001b[3m\u001b[38;5;246m<chr>\u001b[39m\u001b[23m \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setosa\", \"setos…\n"
     ]
    }
   ],
   "source": [
    "# Let's import datasets.xlsx\n",
    "# and store the resulting data frame\n",
    "# in a variable named df\n",
    "df<- read_excel(\"datasets.xlsx\")\n",
    "\n",
    "# Take a glimpse at df\n",
    "df %>% glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: 32\n",
      "Variables: 11\n",
      "$ mpg  \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8…\n",
      "$ cyl  \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8…\n",
      "$ disp \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 1…\n",
      "$ hp   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 18…\n",
      "$ drat \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92…\n",
      "$ wt   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3…\n",
      "$ qsec \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 1…\n",
      "$ vs   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0…\n",
      "$ am   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0…\n",
      "$ gear \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3…\n",
      "$ carb \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2…\n",
      "Observations: 32\n",
      "Variables: 11\n",
      "$ mpg  \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 21.0, 21.0, 22.8, 21.4, 18.7, 18.1, 14.3, 24.4, 22.8, 19.2, 17.8…\n",
      "$ cyl  \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 6, 6, 4, 6, 8, 6, 8, 4, 4, 6, 6, 8, 8, 8, 8, 8, 8, 4, 4, 4, 4, 8…\n",
      "$ disp \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 160.0, 160.0, 108.0, 258.0, 360.0, 225.0, 360.0, 146.7, 140.8, 1…\n",
      "$ hp   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 110, 110, 93, 110, 175, 105, 245, 62, 95, 123, 123, 180, 180, 18…\n",
      "$ drat \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 3.90, 3.90, 3.85, 3.08, 3.15, 2.76, 3.21, 3.69, 3.92, 3.92, 3.92…\n",
      "$ wt   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 2.620, 2.875, 2.320, 3.215, 3.440, 3.460, 3.570, 3.190, 3.150, 3…\n",
      "$ qsec \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 16.46, 17.02, 18.61, 19.44, 17.02, 20.22, 15.84, 20.00, 22.90, 1…\n",
      "$ vs   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0…\n",
      "$ am   \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0…\n",
      "$ gear \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 4, 4, 4, 3, 3, 3, 3, 4, 4, 4, 4, 3, 3, 3, 3, 3, 3, 4, 4, 4, 3, 3…\n",
      "$ carb \u001b[3m\u001b[38;5;246m<dbl>\u001b[39m\u001b[23m 4, 4, 1, 1, 2, 1, 4, 2, 2, 4, 4, 3, 3, 3, 4, 4, 4, 1, 2, 1, 1, 2…\n"
     ]
    }
   ],
   "source": [
    "# Let's try importing the mtcars sheet\n",
    "# of the older xls type spreadsheet\n",
    "# Store the result in df\n",
    "# Use sheet = \"name of sheet\" parameter\n",
    "df <- read_excel(\"datasets.xls\", sheet = \"mtcars\")\n",
    "\n",
    "# glimpse df\n",
    "df %>% glimpse()\n",
    "\n",
    "# glimpse mtcars\n",
    "mtcars %>% glimpse()\n",
    "\n",
    "# Notice that both have the same\n",
    "# number of rows and columns\n",
    "# and the same variable names and order\n",
    "# and the same data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in excel_sheet(\"multi_sheet_xlsx.xlsx\"): could not find function \"excel_sheet\"\n",
     "output_type": "error",
     "traceback": [
      "Error in excel_sheet(\"multi_sheet_xlsx.xlsx\"): could not find function \"excel_sheet\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Let's turn to a less tidy \n",
    "# Excel spreadsheet, multi_sheet_xlsx.xlsx\n",
    "\n",
    "# Open this workbook in Excel and browse it\n",
    "# Be careful not to change anything\n",
    "# Notice the filters\n",
    "# Look through all the sheets\n",
    "# Close the workbook without saving.\n",
    "\n",
    "# List the sheets\n",
    "# Use excel_sheets()\n",
    "excel_sheet(\"multi_sheet_xlsx.xlsx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: `path` does not exist: ‘mulit_sheet_xlsx.xlsx’\n",
     "output_type": "error",
     "traceback": [
      "Error: `path` does not exist: ‘mulit_sheet_xlsx.xlsx’\nTraceback:\n",
      "1. read_excel(\"mulit_sheet_xlsx.xlsx\", sheet = \"Year1999\")",
      "2. check_file(path)",
      "3. stop(\"`path` does not exist: \", sQuote(path), call. = FALSE)"
     ]
    }
   ],
   "source": [
    "# Excel spreadsheet, multi_sheet_xlsx.xlsx\n",
    "# Import each sheet into it's own data frame\n",
    "\n",
    "# Import the first sheet by name\n",
    "# variable: df_year1999\n",
    "df_year1999 <- read_excel(\"mulit_sheet_xlsx.xlsx\", sheet = \"Year1999\")\n",
    "\n",
    "# Glimpse the results\n",
    "df_year199 %>% glimpse()\n",
    "\n",
    "# Import the second sheet by position instead of name\n",
    "# Sheet position starts with 1 for the first sheet\n",
    "# variable: df_year2008\n",
    "df_year2008 <- read_excel(\"multi_sheet_xlsx.xlsx\", sheet = \"Year2008\")\n",
    "\n",
    "# Glimpse the results\n",
    "df_year %>% glimpse()\n",
    "\n",
    "# Import the third sheet by name\n",
    "# variable: df_offset\n",
    "df_offset <- read_excel(\"multi_sheet_xlsx.xlsx\", sheet = \"Offset\")\n",
    "\n",
    "# Glimpse the results\n",
    "df_offset %>% glimpse()\n",
    "\n",
    "# Compare them to mpg\n",
    "\n",
    "mpg %>% glimpse()\n",
    "\n",
    "# Did the Excel filters have any effect?\n",
    "# How well did the data types match the original?\n",
    "# How did the Offset sheet get handled?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(lhs, parent, parent): object 'df_year1999' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(lhs, parent, parent): object 'df_year1999' not found\nTraceback:\n",
      "1. df_year1999 %>% mutate(year = as.integer(year), cyl = as.integer(cyl), \n .     cty = as.integer(cty), hwy = as.integer(hwy))",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)"
     ]
    }
   ],
   "source": [
    "# Let's work on the first two sheets\n",
    "# and fix the issues before we tackle the third one\n",
    "\n",
    "# Let's correct the data types\n",
    "# Excel treats all numbers as floating point\n",
    "# values, and we could do that in R too, \n",
    "# but the purest in me wants to use the \n",
    "# most appropriate data type which is\n",
    "# integer for some variables\n",
    "\n",
    "# Let's remind ourselves what variables should be integers\n",
    "# Review the prior output of glimpse(mpg)\n",
    "# The int columns are:\n",
    "# year, cyl, cty, and hwy\n",
    "\n",
    "# Unfortunately, we don't have \n",
    "# integer available in col_types\n",
    "# We only have \"blank\", \"numeric\", \"date\" or \"text\"\n",
    "# So, we need to fix it after the import\n",
    "# We will use the as.integer() function\n",
    "# inside a mutate() function to do this\n",
    "# We'll assign it to a new data frame variable\n",
    "# but normally we could overwrite the same \n",
    "# variable and reuse it\n",
    "df_year1999_datatypes <- df_year1999 %>%\n",
    "   mutate(year = as.integer(year), \n",
    "          cyl = as.integer(cyl), \n",
    "          cty = as.integer(cty), \n",
    "          hwy = as.integer(hwy))\n",
    "\n",
    "# Glimpse the new data frame\n",
    "df_year1999_datatypes %>% glimpse()\n",
    "\n",
    "# Notice the data types look good. \n",
    "# It still has years other than 1999\n",
    "# Let's fix that next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in eval(lhs, parent, parent): object 'df_year_datatypes' not found\n",
     "output_type": "error",
     "traceback": [
      "Error in eval(lhs, parent, parent): object 'df_year_datatypes' not found\nTraceback:\n",
      "1. df_year_datatypes %>% filter(year == 1999)",
      "2. eval(lhs, parent, parent)",
      "3. eval(lhs, parent, parent)"
     ]
    }
   ],
   "source": [
    "# We want to filter the data so our \n",
    "# data frame has only year 1999 to match the \n",
    "# spreadsheet. Normally, I would rather have a single \n",
    "# data frame with all the data\n",
    "# but this is good learning opportunity\n",
    "\n",
    "# Let's use another variable to store the results\n",
    "# df_year1999_fixed\n",
    "# Use filter() to keep only year 1999\n",
    "df_year1999_fixed <- df_year_datatypes %>% \n",
    "   filter(year == 1999)\n",
    "\n",
    "# Glimpse the results\n",
    "df_year1999_fixed %>% glimpse()\n",
    "\n",
    "# Notice the number of rows compared to the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in parse(text = x, srcfile = src): <text>:14:1: unexpected symbol\n13: # Glimpse result\n14: df_year2008\n    ^\n",
     "output_type": "error",
     "traceback": [
      "Error in parse(text = x, srcfile = src): <text>:14:1: unexpected symbol\n13: # Glimpse result\n14: df_year2008\n    ^\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Let's fix the data types and filter \n",
    "# for year all together using the second sheet\n",
    "# Use the previous code block as a guide\n",
    "# This time pipe the filter() after the mutate\n",
    "# so no new variable is needed\n",
    "df_year2008_fixed <- df_year2008 %>%\n",
    "   mutate(year = as.integer(year), \n",
    "          cyl = as.integer(cyl), \n",
    "          cty = as.integer(cty, \n",
    "          hwy = as.integer(hwy)) %>% \n",
    "   filter(year == 2008)\n",
    "\n",
    "# Glimpse result\n",
    "df_year2008 %>% glimpse()\n",
    "\n",
    "# Notice the integer data types and the \n",
    "# number of rows compared to the full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in df_year1999_fixed %>% bind_rows(df_year2008_fixed): could not find function \"%>%\"\n",
     "output_type": "error",
     "traceback": [
      "Error in df_year1999_fixed %>% bind_rows(df_year2008_fixed): could not find function \"%>%\"\nTraceback:\n"
     ]
    }
   ],
   "source": [
    "# Pretending that we had two spreadsheets\n",
    "# One with the data for one year\n",
    "# and the other for the data from the other year\n",
    "# We really would like to get them into a \n",
    "# single data frame. \n",
    "# When you have a situation where the \n",
    "# column names and data types match up and you simply want to \n",
    "# append them together, then\n",
    "# bind_rows() does the job well.\n",
    "\n",
    "# Combine the two data frames together into a \n",
    "# single data frame name df_allyears\n",
    "df_allyears <- df_year1999_fixed %>%\n",
    "   bind_rows(df_year2008_fixed)\n",
    "\n",
    "# Glimpse the result\n",
    "df_allyears %>% glimpse()\n",
    "\n",
    "# Compare to the original mpg\n",
    "mpg %>% glimpse()\n",
    "\n",
    "# Look at the data in the output carefully\n",
    "# All the data is there but it is in a different\n",
    "# order than the original. \n",
    "# in our combined data frame, all 1999 rows are first\n",
    "# followed by the 2008 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting to the last spreadsheet, Offset\n",
    "# The default import was a disaster\n",
    "# Let's review what it looked like\n",
    "# using glimpse\n",
    "glimpse(df_offset)\n",
    "\n",
    "# Notice no column names \n",
    "# NAs for entire rows and columns\n",
    "# All data types are chr (character strings)\n",
    "# Sure we could clean this up after it is\n",
    "# in a data frame, but if we can give \n",
    "# the read_excel a hint about what we want to import\n",
    "# that may save us a lot of clean up work\n",
    "\n",
    "# To see this more clearly lets look at the \n",
    "# top 5 rows of the data frame\n",
    "df_offset %>% head(5)\n",
    "\n",
    "# Now look at the bottom 10 rows\n",
    "df_offset %>% tail(10)\n",
    "\n",
    "# Notice the first 3 rows should be ignored\n",
    "# and their is some junk at the bottom of the spreadsheet\n",
    "# that should also be ignored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Let's skip the first 3 rows and see how much that helps\n",
    "df_offset <- read_excel(\"multi_sheet_xlsx.xlsx\", sheet = \"Offset\", n = 3)\n",
    "\n",
    "# Glimpse the results\n",
    "df_offset %>% glimpse()\n",
    "\n",
    "# Notice the warning message. \n",
    "# That was the notes at the bottom of the spreadsheet.\n",
    "\n",
    "# It looks like if we remove the last column and change the data types\n",
    "# it will be all fixed up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the last column using select()\n",
    "# Hint: use column number range\n",
    "df_offset_columns <- df_offset %>%\n",
    "   select(1:11)\n",
    "\n",
    "# Glimpse the result\n",
    "df_offset_columns %>% glimpse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's fix the double to integer data types\n",
    "df_offset_fixed <- df_offset_columns %>%\n",
    "   mutate(year = as.integer(year), \n",
    "          cyl = as.integer(cyl), \n",
    "          cty = as.integer(cty), \n",
    "          hwy = as.integer(hwy))\n",
    "\n",
    "# Glimpse result\n",
    "glimpse(df_offset_fixed)\n",
    "\n",
    "# Compare to original mpg\n",
    "glimpse(mpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# drop_na()\n",
    "Drop rows containing missing values. \n",
    "\n",
    "drop_na(data, ...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull up help on drop_na()\n",
    "?drop_na()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's remove the na rows\n",
    "df_offset_fixed <- df_offset_columns %>%\n",
    "   drop_na()\n",
    "\n",
    "# Glimpse result\n",
    "df_offset_fixed %>% glimpse()\n",
    "\n",
    "# Compare to original mpg\n",
    "mpg %>% glimpse()\n",
    "\n",
    "# Perfect match, including row order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "readxl package is under active development. It is developing features to handle this allowing you to provide a cell range like df_offset <- read_excel(\"multi_sheet_xlsx.xlsx\", sheet = \"Offset\", range = \"B4:L238\") and even anchor points so you just need to specify the top left corner cell which is good when you don't how many rows and columns there will be.\n",
    "\n",
    "For now, we can do manual clean up of the data frame and use skip as we did earlier. If that doesn't work well, consider manually selecting the data in Excel and pasting in cell A1 on a new sheet, or if you are going that far, you can just save the sheet as a csv file and import via read_csv to give yourself a few more features during the import.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
